{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Lá»‡nh cho ngÃ³i vÃ  gáº¡ch",
   "id": "feedc6482fd5bc66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# --- Cáº¤U HÃŒNH ---\n",
    "JSON_FILENAME = \"data_viglacera.json\"\n",
    "CATEGORY_URL = { # Key: Ä‘á»‹a chá»‰ loáº¡i sáº£n pháº©m, value: giÃ¡ trá»‹ chá»— pháº§n selector css tuong ung\n",
    "    \"https://viglaceratiles.vn/san-pham/ngoi-lop.html\": \".product-box-tiles\",\n",
    "    \"https://viglaceratiles.vn/san-pham/gach-op-lat.html\": \".product-box\",\n",
    "}\n",
    "\n",
    "# Headers giáº£ láº­p trÃ¬nh duyá»‡t cho requests\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "    'Accept-Language': 'vi-VN,vi;q=0.9,en-US;q=0.8,en;q=0.7'\n",
    "}\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Thiáº¿t láº­p vÃ  khá»Ÿi táº¡o Selenium Driver\"\"\"\n",
    "    chrome_options = Options()\n",
    "    # chrome_options.add_argument(\"--headless\") # Bá» comment náº¿u muá»‘n cháº¡y áº©n\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "def get_all_product_links(url):\n",
    "    \"\"\"\n",
    "    BÆ°á»›c 1: Sá»­ dá»¥ng Selenium Ä‘á»ƒ cuá»™n trang vÃ  láº¥y toÃ n bá»™ LINK sáº£n pháº©m.\n",
    "    Tráº£ vá»: Danh sÃ¡ch (List) cÃ¡c Ä‘Æ°á»ng dáº«n URL.\n",
    "    \"\"\"\n",
    "    driver = setup_driver()\n",
    "    product_links = []\n",
    "\n",
    "    try:\n",
    "        print(f\"ğŸš€ BÆ¯á»šC 1: Khá»Ÿi Ä‘á»™ng Selenium Ä‘á»ƒ láº¥y link tá»«: {url}\")\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # --- Logic cuá»™n trang (Lazy Load) ---\n",
    "        print(\"ğŸ”„ Äang cuá»™n trang...\")\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        while True:\n",
    "            # Cuá»™n xuá»‘ng Ä‘Ã¡y\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2) # Chá» load\n",
    "\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                print(\"-> ÄÃ£ cuá»™n Ä‘áº¿n cuá»‘i trang.\")\n",
    "                break\n",
    "            last_height = new_height\n",
    "            print(\"... Äang táº£i thÃªm ...\")\n",
    "\n",
    "        # --- PhÃ¢n tÃ­ch HTML Ä‘á»ƒ láº¥y Link ---\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        product_items = soup.select('.product-box-tiles')\n",
    "\n",
    "        print(f\"âœ… TÃ¬m tháº¥y {len(product_items)} tháº» sáº£n pháº©m.\")\n",
    "\n",
    "        for item in product_items:\n",
    "            link_tag = item.select_one('a.link-load')\n",
    "            if link_tag and link_tag.get('href'):\n",
    "                full_link = link_tag.get('href')\n",
    "                if not full_link.startswith('http'):\n",
    "                    full_link = \"https://viglaceratiles.vn\" + full_link\n",
    "                product_links.append(full_link)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Lá»—i Selenium: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    # Loáº¡i bá» link trÃ¹ng láº·p (náº¿u cÃ³)\n",
    "    return list(set(product_links))\n",
    "\n",
    "\n",
    "\n",
    "def scrape_product_detail(url):\n",
    "    \"\"\"\n",
    "    Truy cáº­p URL chi tiáº¿t, táº£i HTML vÃ  trÃ­ch xuáº¥t thÃ´ng tin sáº£n pháº©m Viglacera.\n",
    "    \"\"\"\n",
    "    # print(f\"ğŸ”„ Äang xá»­ lÃ½: {url}\") # Bá» comment náº¿u muá»‘n xem log chi tiáº¿t\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, timeout=10)\n",
    "        if response.status_code != 200: return None\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # 1. Láº¥y thÃ´ng tin Cá» Äá»ŠNH (Má»i sáº£n pháº©m Ä‘á»u pháº£i cÃ³)\n",
    "        product_code = soup.select_one('.title-main h2 strong').text.strip() if soup.select_one('.title-main h2 strong') else \"N/A\"\n",
    "\n",
    "        breadcrumb = soup.select_one('.breadcrumb li:last-child a')\n",
    "        collection = breadcrumb.text.strip() if breadcrumb else \"N/A\"\n",
    "\n",
    "        images = []\n",
    "        for img in soup.select('.detail-pic img'):\n",
    "            if img.get('src'):\n",
    "                src = \"https://viglaceratiles.vn\" + img.get('src') if not img.get('src').startswith('http') else img.get('src')\n",
    "                images.append(src)\n",
    "\n",
    "        # 2. Láº¥y thÃ´ng tin Äá»˜NG (Duyá»‡t qua des-item)\n",
    "        # Báº¥t ká»ƒ web cÃ³ \"XÆ°Æ¡ng\", \"Chá»§ng loáº¡i\", \"CÃ´ng nÄƒng\" hay \"Äá»™ dÃ y\"... code Ä‘á»u láº¥y háº¿t.\n",
    "        dynamic_specs = {}\n",
    "        spec_items = soup.select('.des-item')\n",
    "\n",
    "        for item in spec_items:\n",
    "            key_tag = item.select_one('span')\n",
    "            val_tag = item.select_one('h3')\n",
    "\n",
    "            if key_tag and val_tag:\n",
    "                # LÆ°u nguyÃªn vÄƒn tÃªn thuá»™c tÃ­nh (VÃ­ dá»¥: \"KÃ­ch thÆ°á»›c\", \"XÆ°Æ¡ng\", \"Chá»§ng loáº¡i\")\n",
    "                # DÃ¹ng .title() Ä‘á»ƒ viáº¿t hoa chá»¯ cÃ¡i Ä‘áº§u cho Ä‘áº¹p (KÃ­ch ThÆ°á»›c)\n",
    "                key = key_tag.text.strip()\n",
    "                value = val_tag.text.strip()\n",
    "                dynamic_specs[key] = value\n",
    "\n",
    "        # 3. Gá»˜P Dá»® LIá»†U (Merge)\n",
    "        # Táº¡o dictionary chá»©a thÃ´ng tin cÆ¡ báº£n trÆ°á»›c\n",
    "        final_data = {\n",
    "            'URL': url,\n",
    "            'MÃ£ Sáº£n Pháº©m': product_code,\n",
    "            'Bá»™ SÆ°u Táº­p': collection,\n",
    "            'HÃ¬nh áº¢nh': images[0] if images else \"N/A\",\n",
    "            'Danh SÃ¡ch áº¢nh': images\n",
    "        }\n",
    "\n",
    "        # --- ÄÃ‚Y LÃ€ PHáº¦N QUAN TRá»ŒNG NHáº¤T ---\n",
    "        # Gá»™p toÃ n bá»™ thÃ´ng sá»‘ Ä‘á»™ng vÃ o káº¿t quáº£ cuá»‘i cÃ¹ng\n",
    "        # Náº¿u sáº£n pháº©m cÃ³ \"Äá»™ dÃ y\", nÃ³ sáº½ tá»± thÃªm key \"Äá»™ dÃ y\" vÃ o final_data\n",
    "        final_data.update(dynamic_specs)\n",
    "\n",
    "        return final_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Lá»—i: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # 1. Láº¥y danh sÃ¡ch Link\n",
    "    all_links = get_all_product_links(CATEGORY_URL)\n",
    "\n",
    "    if not all_links:\n",
    "        print(\"KhÃ´ng tÃ¬m tháº¥y link nÃ o. Káº¿t thÃºc.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nğŸš€ BÆ¯á»šC 2: Báº¯t Ä‘áº§u cÃ o chi tiáº¿t {len(all_links)} sáº£n pháº©m báº±ng Requests...\")\n",
    "\n",
    "    final_data = []\n",
    "\n",
    "    # 2. VÃ²ng láº·p cÃ o chi tiáº¿t\n",
    "    for index, link in enumerate(all_links):\n",
    "        print(f\"[{index + 1}/{len(all_links)}] Xá»­ lÃ½: {link}\")\n",
    "\n",
    "        detail = scrape_product_detail(link)\n",
    "        if detail:\n",
    "            final_data.append(detail)\n",
    "\n",
    "        # Ngá»§ nháº¹ 1 chÃºt Ä‘á»ƒ trÃ¡nh spam server quÃ¡ nhanh\n",
    "        # time.sleep(0.5)\n",
    "\n",
    "    # 3. LÆ°u ra file JSON\n",
    "    print(f\"\\nğŸ’¾ Äang lÆ°u {len(final_data)} sáº£n pháº©m vÃ o file JSON...\")\n",
    "\n",
    "    with open(JSON_FILENAME, 'w', encoding='utf-8') as f:\n",
    "        # ensure_ascii=False Ä‘á»ƒ hiá»ƒn thá»‹ tiáº¿ng Viá»‡t Ä‘Ãºng\n",
    "        # indent=4 Ä‘á»ƒ format Ä‘áº¹p, dá»… Ä‘á»c\n",
    "        json.dump(final_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"ğŸ‰ HOÃ€N Táº¤T! File lÆ°u táº¡i: {JSON_FILENAME}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "86a898bd1b8f0939"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## á»NG KHÃ ??? AAC",
   "id": "899dc73907cf250d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T19:39:54.932954Z",
     "start_time": "2025-12-11T19:39:41.947771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# --- Cáº¤U HÃŒNH ---\n",
    "JSON_FILENAME = \"data_viglacera.json\"\n",
    "CATEGORY_URL = \"https://viglacera-aac.vn/collections/tat-ca-san-pham\"\n",
    "\n",
    "# Headers giáº£ láº­p trÃ¬nh duyá»‡t cho requests\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "    'Accept-Language': 'vi-VN,vi;q=0.9,en-US;q=0.8,en;q=0.7'\n",
    "}\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Thiáº¿t láº­p vÃ  khá»Ÿi táº¡o Selenium Driver\"\"\"\n",
    "    chrome_options = Options()\n",
    "    # chrome_options.add_argument(\"--headless\") # Bá» comment náº¿u muá»‘n cháº¡y áº©n\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "def get_all_product_links(url):\n",
    "    \"\"\"\n",
    "    BÆ°á»›c 1: Sá»­ dá»¥ng Selenium Ä‘á»ƒ cuá»™n trang vÃ  láº¥y toÃ n bá»™ LINK sáº£n pháº©m.\n",
    "    Tráº£ vá»: Danh sÃ¡ch (List) cÃ¡c Ä‘Æ°á»ng dáº«n URL.\n",
    "    \"\"\"\n",
    "    driver = setup_driver()\n",
    "    product_links = []\n",
    "\n",
    "    try:\n",
    "        print(f\"ğŸš€ BÆ¯á»šC 1: Khá»Ÿi Ä‘á»™ng Selenium Ä‘á»ƒ láº¥y link tá»«: {url}\")\n",
    "        driver.get(url)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # --- Logic cuá»™n trang (Lazy Load) ---\n",
    "        print(\"ğŸ”„ Äang cuá»™n trang...\")\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        while True:\n",
    "            # Cuá»™n xuá»‘ng Ä‘Ã¡y\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2) # Chá» load\n",
    "\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                print(\"-> ÄÃ£ cuá»™n Ä‘áº¿n cuá»‘i trang.\")\n",
    "                break\n",
    "            last_height = new_height\n",
    "            print(\"... Äang táº£i thÃªm ...\")\n",
    "\n",
    "        # --- PhÃ¢n tÃ­ch HTML Ä‘á»ƒ láº¥y Link ---\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        product_items = soup.select('.product-title')\n",
    "\n",
    "        print(f\"âœ… TÃ¬m tháº¥y {len(product_items)} tháº» sáº£n pháº©m.\")\n",
    "\n",
    "        for item in product_items:\n",
    "            link_tag = item.select_one('.product-title a')\n",
    "            if link_tag and link_tag.get('href'):\n",
    "                full_link = link_tag.get('href')\n",
    "                if not full_link.startswith('http'):\n",
    "                    full_link = url + full_link\n",
    "                product_links.append(full_link)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Lá»—i Selenium: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    # Loáº¡i bá» link trÃ¹ng láº·p (náº¿u cÃ³)\n",
    "    return list(set(product_links))\n",
    "\n",
    "\n",
    "\n",
    "def scrape_product_detail(url):\n",
    "    print(f\"ğŸ”„ Äang xá»­ lÃ½: {url}\")\n",
    "    try:\n",
    "        # 1. Gá»­i Request\n",
    "        response = requests.get(url, headers=HEADERS, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"âŒ Lá»—i HTTP: {response.status_code}\")\n",
    "            return None\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # --- 2. Láº¤Y THÃ”NG TIN CÆ  Báº¢N ---\n",
    "\n",
    "        # TÃªn sáº£n pháº©m\n",
    "        name_tag = soup.find('h1', itemprop='name')\n",
    "        product_name = name_tag.text.strip() if name_tag else \"N/A\"\n",
    "\n",
    "        # ThÆ°Æ¡ng hiá»‡u\n",
    "        brand_tag = soup.select_one('.pro-brand a')\n",
    "        brand = brand_tag.text.strip() if brand_tag else \"N/A\"\n",
    "\n",
    "        # Loáº¡i sáº£n pháº©m\n",
    "        type_tag = soup.select_one('.pro-type a')\n",
    "        product_type = type_tag.text.strip() if type_tag else \"N/A\"\n",
    "\n",
    "        # --- 3. Láº¤Y HÃŒNH áº¢NH ---\n",
    "        images = []\n",
    "        # áº¢nh chÃ­nh (Lá»›n)\n",
    "        main_img = soup.select_one('#ProductPhoto img')\n",
    "        if main_img and main_img.get('src'):\n",
    "            src = main_img.get('src')\n",
    "            if src.startswith('//'): src = 'https:' + src\n",
    "            images.append(src)\n",
    "\n",
    "        # áº¢nh phá»¥ (Slider/Thumbnails)\n",
    "        thumb_imgs = soup.select('#sliderproduct img') # Hoáº·c selector cá»§a slider\n",
    "        for img in thumb_imgs:\n",
    "            src = img.get('src')\n",
    "            if src:\n",
    "                if src.startswith('//'): src = 'https:' + src\n",
    "                if src not in images:\n",
    "                    images.append(src)\n",
    "\n",
    "        # --- 4. Xá»¬ LÃ Báº¢NG THÃ”NG Sá» (Tá»° Äá»˜NG HÃ“A Sá» Cá»˜T) ---\n",
    "        specs = {}\n",
    "        table = soup.find('table')\n",
    "        if table:\n",
    "            rows = table.find_all('tr')\n",
    "            for row in rows:\n",
    "                # Láº¥y táº¥t cáº£ text trong cÃ¡c Ã´ (td hoáº·c th)\n",
    "                cols = row.find_all(['td', 'th'])\n",
    "                row_data = [c.text.strip() for c in cols if c.text.strip()]\n",
    "\n",
    "                # Bá» qua dÃ²ng rá»—ng hoáº·c dÃ²ng tiÃªu Ä‘á» báº£ng (chá»©a chá»¯ \"Chá»‰ tiÃªu\", \"ThÃ´ng sá»‘\")\n",
    "                if not row_data: continue\n",
    "                first_cell_lower = row_data[0].lower()\n",
    "                if 'chá»‰ tiÃªu' in first_cell_lower or 'thÃ´ng sá»‘' in first_cell_lower or 'Ä‘Æ¡n vá»‹' in first_cell_lower:\n",
    "                    continue\n",
    "\n",
    "                # LOGIC DYNAMIC:\n",
    "                # Cá»™t Ä‘áº§u = Key (TÃªn)\n",
    "                # Cá»™t cuá»‘i = Value (GiÃ¡ trá»‹)\n",
    "                # CÃ¡c cá»™t giá»¯a = ÄÆ¡n vá»‹ tÃ­nh (Gá»™p vÃ o Key)\n",
    "                if len(row_data) >= 2:\n",
    "                    key_name = row_data[0]\n",
    "                    value = row_data[-1]\n",
    "\n",
    "                    if len(row_data) > 2:\n",
    "                        # CÃ³ cá»™t giá»¯a -> Gá»™p vÃ o tÃªn\n",
    "                        units = \" \".join(row_data[1:-1])\n",
    "                        full_key = f\"{key_name} ({units})\"\n",
    "                    else:\n",
    "                        # Chá»‰ cÃ³ 2 cá»™t -> TÃªn thuáº§n tÃºy\n",
    "                        full_key = key_name\n",
    "\n",
    "                    specs[full_key] = value\n",
    "\n",
    "        # --- 5. Xá»¬ LÃ THÃ”NG TIN MÃ” Táº¢ (LIST UL/LI) ---\n",
    "        info_dict = {}\n",
    "\n",
    "        # TÃ¬m tháº» UL chá»©a thÃ´ng tin (ThÆ°á»ng náº±m sau H2 \"ThÃ´ng tin sáº£n pháº©m\")\n",
    "        headers = soup.find_all('h2')\n",
    "        target_ul = None\n",
    "        for h2 in headers:\n",
    "            if \"THÃ”NG TIN\" in h2.text.upper() or \"TÃNH NÄ‚NG\" in h2.text.upper():\n",
    "                # TÃ¬m tháº» UL hoáº·c DIV chá»©a UL ngay sau tiÃªu Ä‘á»\n",
    "                sibling = h2.find_next_sibling(['ul', 'div'])\n",
    "                if sibling:\n",
    "                    if sibling.name == 'div':\n",
    "                        target_ul = sibling.find('ul')\n",
    "                    else:\n",
    "                        target_ul = sibling\n",
    "                    if target_ul: break # TÃ¬m tháº¥y thÃ¬ dá»«ng\n",
    "\n",
    "        # Náº¿u khÃ´ng tÃ¬m tháº¥y theo H2, tÃ¬m UL Ä‘áº§u tiÃªn trong ná»™i dung\n",
    "        if not target_ul:\n",
    "            content_div = soup.find('div', class_='pro-tabcontent')\n",
    "            if content_div:\n",
    "                target_ul = content_div.find('ul')\n",
    "\n",
    "        # Duyá»‡t qua cÃ¡c dÃ²ng li Ä‘á»ƒ láº¥y dá»¯ liá»‡u\n",
    "        if target_ul:\n",
    "            lis = target_ul.find_all('li')\n",
    "            for i, li in enumerate(lis):\n",
    "                text = li.text.strip()\n",
    "                if ':' in text:\n",
    "                    # TÃ¡ch theo dáº¥u hai cháº¥m Ä‘áº§u tiÃªn\n",
    "                    parts = text.split(':', 1)\n",
    "                    k = parts[0].strip()\n",
    "                    v = parts[1].strip()\n",
    "                    info_dict[k] = v\n",
    "                else:\n",
    "                    # DÃ²ng khÃ´ng cÃ³ key:value -> Äáº·t key tá»± Ä‘á»™ng\n",
    "                    info_dict[f\"Info_{i+1}\"] = text\n",
    "\n",
    "        # --- 6. Tá»”NG Há»¢P Káº¾T QUáº¢ ---\n",
    "        final_data = {\n",
    "            'URL': url,\n",
    "            'TÃªn Sáº£n Pháº©m': product_name,\n",
    "            'ThÆ°Æ¡ng Hiá»‡u': brand,\n",
    "            'Loáº¡i Sáº£n Pháº©m': product_type,\n",
    "            'áº¢nh Äáº¡i Diá»‡n': images[0] if images else \"N/A\",\n",
    "            'Danh SÃ¡ch áº¢nh': images\n",
    "        }\n",
    "\n",
    "        # Gá»™p thÃ´ng tin mÃ´ táº£\n",
    "        final_data.update(info_dict)\n",
    "        # Gá»™p thÃ´ng sá»‘ ká»¹ thuáº­t\n",
    "        final_data.update(specs)\n",
    "\n",
    "        return final_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Lá»—i ngoáº¡i lá»‡: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # 1. Láº¥y danh sÃ¡ch Link\n",
    "    all_links = get_all_product_links(CATEGORY_URL)\n",
    "\n",
    "    if not all_links:\n",
    "        print(\"KhÃ´ng tÃ¬m tháº¥y link nÃ o. Káº¿t thÃºc.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nğŸš€ BÆ¯á»šC 2: Báº¯t Ä‘áº§u cÃ o chi tiáº¿t {len(all_links)} sáº£n pháº©m báº±ng Requests...\")\n",
    "\n",
    "    final_data = []\n",
    "\n",
    "    # 2. VÃ²ng láº·p cÃ o chi tiáº¿t\n",
    "    for index, link in enumerate(all_links):\n",
    "        print(f\"[{index + 1}/{len(all_links)}] Xá»­ lÃ½: {link}\")\n",
    "\n",
    "        detail = scrape_product_detail(link)\n",
    "        if detail:\n",
    "            final_data.append(detail)\n",
    "\n",
    "        # Ngá»§ nháº¹ 1 chÃºt Ä‘á»ƒ trÃ¡nh spam server quÃ¡ nhanh\n",
    "        # time.sleep(0.5)\n",
    "\n",
    "    # 3. LÆ°u ra file JSON\n",
    "    print(f\"\\nğŸ’¾ Äang lÆ°u {len(final_data)} sáº£n pháº©m vÃ o file JSON...\")\n",
    "\n",
    "    with open(JSON_FILENAME, 'w', encoding='utf-8') as f:\n",
    "        # ensure_ascii=False Ä‘á»ƒ hiá»ƒn thá»‹ tiáº¿ng Viá»‡t Ä‘Ãºng\n",
    "        # indent=4 Ä‘á»ƒ format Ä‘áº¹p, dá»… Ä‘á»c\n",
    "        json.dump(final_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"ğŸ‰ HOÃ€N Táº¤T! File lÆ°u táº¡i: {JSON_FILENAME}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "85a03cb98b416ff6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ BÆ¯á»šC 1: Khá»Ÿi Ä‘á»™ng Selenium Ä‘á»ƒ láº¥y link tá»«: https://viglacera-aac.vn/collections/tat-ca-san-pham\n",
      "ğŸ”„ Äang cuá»™n trang...\n",
      "-> ÄÃ£ cuá»™n Ä‘áº¿n cuá»‘i trang.\n",
      "âœ… TÃ¬m tháº¥y 6 tháº» sáº£n pháº©m.\n",
      "\n",
      "ğŸš€ BÆ¯á»šC 2: Báº¯t Ä‘áº§u cÃ o chi tiáº¿t 6 sáº£n pháº©m báº±ng Requests...\n",
      "[1/6] Xá»­ lÃ½: https://viglacera-aac.vn/collections/tat-ca-san-pham/products/san-pham-10\n",
      "ğŸ”„ Äang xá»­ lÃ½: https://viglacera-aac.vn/collections/tat-ca-san-pham/products/san-pham-10\n",
      "[2/6] Xá»­ lÃ½: https://viglacera-aac.vn/collections/tat-ca-san-pham/products/san-pham-12\n",
      "ğŸ”„ Äang xá»­ lÃ½: https://viglacera-aac.vn/collections/tat-ca-san-pham/products/san-pham-12\n",
      "[3/6] Xá»­ lÃ½: https://viglacera-aac.vn/collections/tat-ca-san-pham/products/san-pham-7\n",
      "ğŸ”„ Äang xá»­ lÃ½: https://viglacera-aac.vn/collections/tat-ca-san-pham/products/san-pham-7\n",
      "[4/6] Xá»­ lÃ½: https://viglacera-aac.vn/collections/tat-ca-san-pham/products/san-pham-11\n",
      "ğŸ”„ Äang xá»­ lÃ½: https://viglacera-aac.vn/collections/tat-ca-san-pham/products/san-pham-11\n",
      "[5/6] Xá»­ lÃ½: https://viglacera-aac.vn/collections/tat-ca-san-pham/products/san-pham-9\n",
      "ğŸ”„ Äang xá»­ lÃ½: https://viglacera-aac.vn/collections/tat-ca-san-pham/products/san-pham-9\n",
      "[6/6] Xá»­ lÃ½: https://viglacera-aac.vn/collections/tat-ca-san-pham/products/san-pham-8\n",
      "ğŸ”„ Äang xá»­ lÃ½: https://viglacera-aac.vn/collections/tat-ca-san-pham/products/san-pham-8\n",
      "\n",
      "ğŸ’¾ Äang lÆ°u 6 sáº£n pháº©m vÃ o file JSON...\n",
      "ğŸ‰ HOÃ€N Táº¤T! File lÆ°u táº¡i: data_viglacera.json\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d8e8a9cf86d9fa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
