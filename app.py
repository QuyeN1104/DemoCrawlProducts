import streamlit as st
import json
from scrapers import ViglaceraTilesScraper, ViglaceraAACScraper, VthmGroupScraper

# --- C·∫§U H√åNH ---
OPTIONS = {
    "G·∫°ch ·ªêp L√°t (Viglacera Tiles)": {
        "url": "https://viglaceratiles.vn/san-pham/gach-op-lat.html",
        "scraper_class": ViglaceraTilesScraper,
        "item_selector": ".product-box",
        "link_selector": "a.link-load"
    },
    "Ng√≥i L·ª£p (Viglacera Tiles)": {
        "url": "https://viglaceratiles.vn/san-pham/ngoi-lop.html",
        "scraper_class": ViglaceraTilesScraper,
        "item_selector": ".product-box-tiles",
        "link_selector": "a.link-load"
    },
    "S·∫£n Ph·∫©m AAC (Viglacera AAC)": {
        "url": "https://viglacera-aac.vn/collections/tat-ca-san-pham",
        "scraper_class": ViglaceraAACScraper,
        "item_selector": ".product-title",
        "link_selector": "a"
    },
    "S·∫£n ph·∫©m VTHM Group": {
        "url": "https://vthmgroup.vn/san-pham",
        "scraper_class": VthmGroupScraper,
        # Selector n√†y tr·ªè th·∫≥ng v√†o th·∫ª <a> bao quanh s·∫£n ph·∫©m
        "item_selector": "a.block.group.cursor-pointer",
        # ƒê·ªÉ tr·ªëng link_selector b√°o hi·ªáu cho bot bi·∫øt item ch√≠nh l√† link
        "link_selector": None
    }
}

# --- GIAO DI·ªÜN WEB ---
st.set_page_config(page_title="Viglacera Data Tool", page_icon="üì•", layout="centered")

st.title("üì• Tool T·∫£i D·ªØ Li·ªáu T·ª± ƒê·ªông")
st.write("Ch·ªçn danh m·ª•c s·∫£n ph·∫©m v√† nh·∫•n n√∫t ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
st.markdown("---")

# 1. Menu ch·ªçn
option_name = st.selectbox("Ch·ªçn lo·∫°i s·∫£n ph·∫©m:", list(OPTIONS.keys()))
config = OPTIONS[option_name]

# 2. N√∫t ch·∫°y
if st.button("üöÄ B·∫Øt ƒë·∫ßu l·∫•y d·ªØ li·ªáu", type="primary"):

    # Kh·ªüi t·∫°o class x·ª≠ l√Ω t∆∞∆°ng ·ª©ng
    ScraperClass = config["scraper_class"]
    bot = ScraperClass()

    # --- B∆Ø·ªöC 1: L·∫§Y LINK (Selenium) ---
    status = st.status("ƒêang k·∫øt n·ªëi m√°y ch·ªß...", expanded=True)

    links = bot.get_links(
        url=config['url'],
        item_selector=config['item_selector'],
        link_selector=config['link_selector'],
        progress_callback=status.write
    )

    status.update(label="‚úÖ ƒê√£ k·∫øt n·ªëi xong!", state="complete", expanded=False)

    if not links:
        st.error("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m n√†o. Vui l√≤ng th·ª≠ l·∫°i sau.")
    else:
        st.success(f"ƒê√£ t√¨m th·∫•y **{len(links)}** s·∫£n ph·∫©m. ƒêang t·∫£i chi ti·∫øt...")

        # --- B∆Ø·ªöC 2: C√ÄO CHI TI·∫æT (Requests) ---
        my_bar = st.progress(0)
        txt_status = st.empty()

        # G·ªçi h√†m c√†o danh s√°ch
        data = bot.scrape_details_list(links, progress_bar=my_bar, status_text=txt_status)

        # D·ªçn d·∫πp giao di·ªán khi xong
        my_bar.empty()
        txt_status.empty()

        if data:
            st.balloons()
            st.success("üéâ X·ª≠ l√Ω ho√†n t·∫•t!")

            # Chu·∫©n b·ªã file JSON
            json_str = json.dumps(data, ensure_ascii=False, indent=4)
            file_name_clean = option_name.split('(')[0].strip().replace(' ', '_').lower()
            file_name = f"data_{file_name_clean}.json"

            # N√∫t t·∫£i xu·ªëng
            st.download_button(
                label=f"üì• T·∫£i xu·ªëng file {file_name}",
                data=json_str,
                file_name=file_name,
                mime="application/json",
                type="primary"
            )
        else:
            st.warning("ƒê√£ ch·∫°y xong nh∆∞ng kh√¥ng thu th·∫≠p ƒë∆∞·ª£c d·ªØ li·ªáu chi ti·∫øt.")